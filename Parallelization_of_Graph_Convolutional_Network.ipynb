{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPDO9mWOoX8LMO8pUlG6L1F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CHIN-HUA/AI/blob/main/Parallelization_of_Graph_Convolutional_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGnP66582INd",
        "outputId": "007aa3b5-007f-4ca0-b144-8aa57b4ccee7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bin    cuda\tcuda-11.8  games\t       include\tlib64\t   man\t share\n",
            "colab  cuda-11\tetc\t   _gcs_config_ops.so  lib\tlicensing  sbin  src\n"
          ]
        }
      ],
      "source": [
        "# To show that if there is cuda tookit installed\n",
        "!ls /usr/local"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To show that if there is cuda tookit installed\n",
        "!ls /usr/local"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nmu0aDLV2Nb3",
        "outputId": "33f20ad4-41ec-4f13-e41b-c4ab657e1348"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bin    cuda\tcuda-11.8  games\t       include\tlib64\t   man\t share\n",
            "colab  cuda-11\tetc\t   _gcs_config_ops.so  lib\tlicensing  sbin  src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To show the property of the nvidia card(On my one, I use the K80)\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpnOyBkV2Pho",
        "outputId": "f587784c-fc2c-432e-b075-2446913b0e64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon May 15 14:41:50 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a cu file contain the host and kernel code\n",
        "%%writefile hello.cu\n",
        "\n",
        "#include <iostream>\n",
        "#include <cuda.h>\n",
        "\n",
        "__global__ void hello(void)\n",
        "{\n",
        "  printf(\"GPU: Hello!\\n\");\n",
        "}\n",
        "int main(int argc,char **argv)\n",
        "{\n",
        "  printf(\"CPU: Hello!\\n\");\n",
        "  hello<<<1,10>>>();\n",
        "  cudaDeviceReset();\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxYiEwi96kgc",
        "outputId": "3edaf0b6-c693-4e56-9614-5edb7bff7511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting hello.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -Wno-deprecated-gpu-targets hello.cu -o hello\n",
        "\n",
        "!./hello"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYwH42En7Awq",
        "outputId": "38b1562e-9c83-4851-da25-d7d5c7d2a35e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU: Hello!\n",
            "GPU: Hello!\n",
            "GPU: Hello!\n",
            "GPU: Hello!\n",
            "GPU: Hello!\n",
            "GPU: Hello!\n",
            "GPU: Hello!\n",
            "GPU: Hello!\n",
            "GPU: Hello!\n",
            "GPU: Hello!\n",
            "GPU: Hello!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "MIT License\n",
        "Copyright (c) 2020 Ronald Seoh\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE.\n",
        "'''\n",
        "\n",
        "# torch.device / CUDA Setup\n",
        "import torch\n",
        "\n",
        "use_cuda = True\n",
        "use_colab_tpu = False\n",
        "colab_tpu_available = False\n",
        "\n",
        "if use_colab_tpu:\n",
        "    try:\n",
        "        assert os.environ['COLAB_TPU_ADDR']\n",
        "        colab_tpu_available = True\n",
        "    except:\n",
        "        colab_tpu_available = True\n",
        "\n",
        "if use_cuda and torch.cuda.is_available():\n",
        "    torch_device = torch.device('cuda')\n",
        "\n",
        "    # Set this to True to make your output immediately reproducible\n",
        "    # Note: https://pytorch.org/docs/stable/notes/randomness.html\n",
        "    torch.backends.cudnn.deterministic = False\n",
        "    \n",
        "    # Disable 'benchmark' mode: Set this False if you want to measure running times more fairly\n",
        "    # Note: https://discuss.pytorch.org/t/what-does-torch-backends-cudnn-benchmark-do/5936\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    \n",
        "    # Faster Host to GPU copies with page-locked memory\n",
        "    use_pin_memory = True \n",
        "\n",
        "    # CUDA libraries version information\n",
        "    print(\"CUDA Version: \" + str(torch.version.cuda))\n",
        "    print(\"cuDNN Version: \" + str(torch.backends.cudnn.version()))\n",
        "    print(\"CUDA Device Name: \" + str(torch.cuda.get_device_name()))\n",
        "    print(\"CUDA Capabilities: \"+ str(torch.cuda.get_device_capability()))\n",
        "\n",
        "elif use_colab_tpu and colab_tpu_available:\n",
        "    # This needs to be installed separately\n",
        "    # https://github.com/pytorch/xla/blob/master/contrib/colab/getting-started.ipynb\n",
        "    import torch_xla \n",
        "    import torch_xla.core.xla_model as xm\n",
        "\n",
        "    torch_device = xm.xla_device()\n",
        "\n",
        "else:\n",
        "    torch_device = torch.device('cpu')\n",
        "    use_pin_memory = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxirNJYl754r",
        "outputId": "d917708f-fc42-4c43-d90d-14cc1dafe719"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA Version: 11.8\n",
            "cuDNN Version: 8700\n",
            "CUDA Device Name: Tesla T4\n",
            "CUDA Capabilities: (7, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/hengdashi/cuda_gcn.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbSpnYZY81FT",
        "outputId": "652a86ec-5dc4-42e0-f5ca-1f9bb2b33481"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cuda_gcn'...\n",
            "remote: Enumerating objects: 425, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 425 (delta 4), reused 13 (delta 4), pack-reused 410\u001b[K\n",
            "Receiving objects: 100% (425/425), 21.89 MiB | 28.93 MiB/s, done.\n",
            "Resolving deltas: 100% (230/230), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ./cuda_gcn/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lndgcMHs9oZO",
        "outputId": "eb14cd79-e112-4e2b-9582-c8757d8982d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data.tgz  README.md\t     reddit_preprocess.py  src\n",
            "Makefile  reddit_edges.json  report\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n",
        "!make cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USmVhXMYCkCJ",
        "outputId": "10aefbca-d587-4404-9c56-6ee5b31e7c42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda_gcn  Makefile   reddit_edges.json\t   report   src\n",
            "data.tgz  README.md  reddit_preprocess.py  seq_gcn\n",
            "nvcc -O3 -std=c++11 -Isrc -Isrc/common -Isrc/seq -Isrc/cuda src/cudamain.o src/common/parser.o src/common/timer.o src/seq/gcn.o src/seq/module.o src/seq/optim.o src/seq/rand.o src/seq/sparse.o src/seq/variable.o src/cuda/cuda_gcn.o src/cuda/cuda_kernel.o src/cuda/cuda_module.o src/cuda/cuda_variable.o -o cuda_gcn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n",
        "!tar -xvzf data.tgz\n",
        "\n",
        "!./cuda_gcn cora"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfkmSYHOE5yF",
        "outputId": "535d33c7-41d4-43e8-e6c3-5e86144e1cd1"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda_gcn  data.tgz  README.md\t       reddit_preprocess.py  seq_gcn\n",
            "data\t  Makefile  reddit_edges.json  report\t\t     src\n",
            "data/citeseer.graph\n",
            "data/citeseer.split\n",
            "data/citeseer.svmlight\n",
            "data/cora.graph\n",
            "data/cora.split\n",
            "data/cora.svmlight\n",
            "data/pubmed.graph\n",
            "data/pubmed.split\n",
            "data/pubmed.svmlight\n",
            "Parse Graph Succeeded.\n",
            "Parse Node Succeeded.\n",
            "Parse Split Succeeded.\n",
            "RUNNING ON GPU\n",
            "epoch=1 train_loss=1.95439 train_acc=0.11429 val_loss=1.95068 val_acc=0.17200 time=0.00282\n",
            "epoch=2 train_loss=1.94962 train_acc=0.22857 val_loss=1.94731 val_acc=0.33400 time=0.00259\n",
            "epoch=3 train_loss=1.94452 train_acc=0.42857 val_loss=1.94432 val_acc=0.48400 time=0.00254\n",
            "epoch=4 train_loss=1.94004 train_acc=0.61429 val_loss=1.94142 val_acc=0.55600 time=0.00258\n",
            "epoch=5 train_loss=1.93708 train_acc=0.59286 val_loss=1.93847 val_acc=0.57400 time=0.00257\n",
            "epoch=6 train_loss=1.92908 train_acc=0.68571 val_loss=1.93540 val_acc=0.59200 time=0.00255\n",
            "epoch=7 train_loss=1.92625 train_acc=0.67857 val_loss=1.93241 val_acc=0.57200 time=0.00265\n",
            "epoch=8 train_loss=1.92213 train_acc=0.66429 val_loss=1.92948 val_acc=0.55200 time=0.00282\n",
            "epoch=9 train_loss=1.91683 train_acc=0.65000 val_loss=1.92658 val_acc=0.55200 time=0.00262\n",
            "epoch=10 train_loss=1.91483 train_acc=0.68571 val_loss=1.92386 val_acc=0.55400 time=0.00259\n",
            "epoch=11 train_loss=1.90290 train_acc=0.71429 val_loss=1.92111 val_acc=0.57000 time=0.00260\n",
            "epoch=12 train_loss=1.90172 train_acc=0.75714 val_loss=1.91831 val_acc=0.58200 time=0.00265\n",
            "epoch=13 train_loss=1.89292 train_acc=0.68571 val_loss=1.91541 val_acc=0.58600 time=0.00276\n",
            "epoch=14 train_loss=1.89269 train_acc=0.67857 val_loss=1.91244 val_acc=0.59200 time=0.00277\n",
            "epoch=15 train_loss=1.88609 train_acc=0.71429 val_loss=1.90941 val_acc=0.59400 time=0.00270\n",
            "epoch=16 train_loss=1.87587 train_acc=0.75714 val_loss=1.90637 val_acc=0.59400 time=0.00262\n",
            "epoch=17 train_loss=1.87312 train_acc=0.72857 val_loss=1.90334 val_acc=0.59600 time=0.00255\n",
            "epoch=18 train_loss=1.86466 train_acc=0.75000 val_loss=1.90034 val_acc=0.60400 time=0.00256\n",
            "epoch=19 train_loss=1.85495 train_acc=0.77143 val_loss=1.89726 val_acc=0.60800 time=0.00258\n",
            "epoch=20 train_loss=1.86024 train_acc=0.72143 val_loss=1.89424 val_acc=0.61600 time=0.00268\n",
            "epoch=21 train_loss=1.84595 train_acc=0.72857 val_loss=1.89129 val_acc=0.62000 time=0.00259\n",
            "epoch=22 train_loss=1.85678 train_acc=0.71429 val_loss=1.88839 val_acc=0.62200 time=0.00256\n",
            "epoch=23 train_loss=1.83941 train_acc=0.69286 val_loss=1.88544 val_acc=0.62400 time=0.00259\n",
            "epoch=24 train_loss=1.82481 train_acc=0.74286 val_loss=1.88245 val_acc=0.62600 time=0.00258\n",
            "epoch=25 train_loss=1.81998 train_acc=0.72143 val_loss=1.87940 val_acc=0.62600 time=0.00258\n",
            "epoch=26 train_loss=1.81811 train_acc=0.65714 val_loss=1.87617 val_acc=0.62400 time=0.00257\n",
            "epoch=27 train_loss=1.80160 train_acc=0.72143 val_loss=1.87269 val_acc=0.63000 time=0.00254\n",
            "epoch=28 train_loss=1.80242 train_acc=0.75000 val_loss=1.86918 val_acc=0.62400 time=0.00256\n",
            "epoch=29 train_loss=1.79871 train_acc=0.70000 val_loss=1.86550 val_acc=0.62600 time=0.00258\n",
            "epoch=30 train_loss=1.77253 train_acc=0.75000 val_loss=1.86170 val_acc=0.62800 time=0.00256\n",
            "epoch=31 train_loss=1.80053 train_acc=0.75714 val_loss=1.85796 val_acc=0.63000 time=0.00255\n",
            "epoch=32 train_loss=1.76547 train_acc=0.70000 val_loss=1.85423 val_acc=0.63800 time=0.00257\n",
            "epoch=33 train_loss=1.77072 train_acc=0.74286 val_loss=1.85057 val_acc=0.63800 time=0.00256\n",
            "epoch=34 train_loss=1.76086 train_acc=0.76429 val_loss=1.84680 val_acc=0.63800 time=0.00270\n",
            "epoch=35 train_loss=1.73152 train_acc=0.71429 val_loss=1.84315 val_acc=0.64200 time=0.00272\n",
            "epoch=36 train_loss=1.74457 train_acc=0.71429 val_loss=1.83935 val_acc=0.64800 time=0.00272\n",
            "epoch=37 train_loss=1.73955 train_acc=0.79286 val_loss=1.83551 val_acc=0.64600 time=0.00274\n",
            "epoch=38 train_loss=1.71805 train_acc=0.76429 val_loss=1.83163 val_acc=0.65000 time=0.00274\n",
            "epoch=39 train_loss=1.70234 train_acc=0.77857 val_loss=1.82775 val_acc=0.65400 time=0.00267\n",
            "epoch=40 train_loss=1.69872 train_acc=0.72857 val_loss=1.82375 val_acc=0.65200 time=0.00262\n",
            "epoch=41 train_loss=1.68179 train_acc=0.72143 val_loss=1.81978 val_acc=0.64800 time=0.00276\n",
            "epoch=42 train_loss=1.67362 train_acc=0.74286 val_loss=1.81588 val_acc=0.64400 time=0.00273\n",
            "epoch=43 train_loss=1.66464 train_acc=0.77857 val_loss=1.81183 val_acc=0.64600 time=0.00274\n",
            "epoch=44 train_loss=1.68578 train_acc=0.76429 val_loss=1.80796 val_acc=0.65200 time=0.00281\n",
            "epoch=45 train_loss=1.68087 train_acc=0.74286 val_loss=1.80399 val_acc=0.65800 time=0.00273\n",
            "epoch=46 train_loss=1.65093 train_acc=0.77857 val_loss=1.79991 val_acc=0.65600 time=0.00273\n",
            "epoch=47 train_loss=1.62874 train_acc=0.77857 val_loss=1.79565 val_acc=0.65400 time=0.00271\n",
            "epoch=48 train_loss=1.62627 train_acc=0.73571 val_loss=1.79143 val_acc=0.65000 time=0.00272\n",
            "epoch=49 train_loss=1.63725 train_acc=0.74286 val_loss=1.78714 val_acc=0.65400 time=0.00267\n",
            "epoch=50 train_loss=1.62506 train_acc=0.75000 val_loss=1.78290 val_acc=0.65400 time=0.00264\n",
            "epoch=51 train_loss=1.58169 train_acc=0.77143 val_loss=1.77860 val_acc=0.65000 time=0.00265\n",
            "epoch=52 train_loss=1.59328 train_acc=0.70714 val_loss=1.77427 val_acc=0.65000 time=0.00250\n",
            "epoch=53 train_loss=1.56798 train_acc=0.76429 val_loss=1.76985 val_acc=0.65600 time=0.00227\n",
            "epoch=54 train_loss=1.54764 train_acc=0.74286 val_loss=1.76546 val_acc=0.65400 time=0.00222\n",
            "epoch=55 train_loss=1.55464 train_acc=0.76429 val_loss=1.76066 val_acc=0.65400 time=0.00222\n",
            "epoch=56 train_loss=1.58385 train_acc=0.75714 val_loss=1.75584 val_acc=0.65200 time=0.00216\n",
            "epoch=57 train_loss=1.54061 train_acc=0.76429 val_loss=1.75088 val_acc=0.65600 time=0.00221\n",
            "epoch=58 train_loss=1.48966 train_acc=0.77143 val_loss=1.74586 val_acc=0.65400 time=0.00229\n",
            "epoch=59 train_loss=1.53287 train_acc=0.75000 val_loss=1.74106 val_acc=0.65800 time=0.00222\n",
            "epoch=60 train_loss=1.49794 train_acc=0.77143 val_loss=1.73622 val_acc=0.65400 time=0.00223\n",
            "epoch=61 train_loss=1.53133 train_acc=0.75714 val_loss=1.73117 val_acc=0.65600 time=0.00224\n",
            "epoch=62 train_loss=1.50424 train_acc=0.76429 val_loss=1.72645 val_acc=0.66000 time=0.00218\n",
            "epoch=63 train_loss=1.50892 train_acc=0.77143 val_loss=1.72187 val_acc=0.66200 time=0.00220\n",
            "epoch=64 train_loss=1.47988 train_acc=0.78571 val_loss=1.71718 val_acc=0.66000 time=0.00218\n",
            "epoch=65 train_loss=1.48625 train_acc=0.78571 val_loss=1.71253 val_acc=0.66200 time=0.00208\n",
            "epoch=66 train_loss=1.44256 train_acc=0.75714 val_loss=1.70763 val_acc=0.66400 time=0.00209\n",
            "epoch=67 train_loss=1.42777 train_acc=0.79286 val_loss=1.70272 val_acc=0.67200 time=0.00221\n",
            "epoch=68 train_loss=1.42749 train_acc=0.77857 val_loss=1.69777 val_acc=0.67200 time=0.00222\n",
            "epoch=69 train_loss=1.43950 train_acc=0.82143 val_loss=1.69272 val_acc=0.67200 time=0.00231\n",
            "epoch=70 train_loss=1.40804 train_acc=0.79286 val_loss=1.68751 val_acc=0.67400 time=0.00216\n",
            "epoch=71 train_loss=1.37858 train_acc=0.78571 val_loss=1.68242 val_acc=0.67200 time=0.00215\n",
            "epoch=72 train_loss=1.41455 train_acc=0.80000 val_loss=1.67744 val_acc=0.67200 time=0.00216\n",
            "epoch=73 train_loss=1.38248 train_acc=0.77857 val_loss=1.67244 val_acc=0.67400 time=0.00216\n",
            "epoch=74 train_loss=1.40331 train_acc=0.80714 val_loss=1.66732 val_acc=0.68400 time=0.00217\n",
            "epoch=75 train_loss=1.39303 train_acc=0.80714 val_loss=1.66239 val_acc=0.68200 time=0.00223\n",
            "epoch=76 train_loss=1.32032 train_acc=0.82857 val_loss=1.65725 val_acc=0.68000 time=0.00363\n",
            "epoch=77 train_loss=1.34412 train_acc=0.76429 val_loss=1.65214 val_acc=0.67800 time=0.00219\n",
            "epoch=78 train_loss=1.31745 train_acc=0.83571 val_loss=1.64702 val_acc=0.67800 time=0.00218\n",
            "epoch=79 train_loss=1.33382 train_acc=0.82143 val_loss=1.64199 val_acc=0.67800 time=0.00219\n",
            "epoch=80 train_loss=1.35559 train_acc=0.82143 val_loss=1.63740 val_acc=0.68000 time=0.00218\n",
            "epoch=81 train_loss=1.33310 train_acc=0.87143 val_loss=1.63282 val_acc=0.68400 time=0.00215\n",
            "epoch=82 train_loss=1.30822 train_acc=0.84286 val_loss=1.62838 val_acc=0.68400 time=0.00223\n",
            "epoch=83 train_loss=1.33249 train_acc=0.82143 val_loss=1.62387 val_acc=0.68200 time=0.00216\n",
            "epoch=84 train_loss=1.30857 train_acc=0.82857 val_loss=1.61952 val_acc=0.68600 time=0.00218\n",
            "epoch=85 train_loss=1.36386 train_acc=0.80714 val_loss=1.61494 val_acc=0.68600 time=0.00217\n",
            "epoch=86 train_loss=1.24587 train_acc=0.80714 val_loss=1.61035 val_acc=0.68600 time=0.00218\n",
            "epoch=87 train_loss=1.25758 train_acc=0.85000 val_loss=1.60582 val_acc=0.68800 time=0.00217\n",
            "epoch=88 train_loss=1.26044 train_acc=0.84286 val_loss=1.60117 val_acc=0.69000 time=0.00217\n",
            "epoch=89 train_loss=1.23613 train_acc=0.84286 val_loss=1.59675 val_acc=0.69200 time=0.00217\n",
            "epoch=90 train_loss=1.26555 train_acc=0.85714 val_loss=1.59241 val_acc=0.69200 time=0.00216\n",
            "epoch=91 train_loss=1.23940 train_acc=0.87857 val_loss=1.58798 val_acc=0.69600 time=0.00216\n",
            "epoch=92 train_loss=1.13112 train_acc=0.86429 val_loss=1.58325 val_acc=0.69600 time=0.00216\n",
            "epoch=93 train_loss=1.23892 train_acc=0.85714 val_loss=1.57864 val_acc=0.69800 time=0.00219\n",
            "epoch=94 train_loss=1.20048 train_acc=0.82143 val_loss=1.57419 val_acc=0.70200 time=0.00237\n",
            "epoch=95 train_loss=1.22899 train_acc=0.86429 val_loss=1.56981 val_acc=0.70800 time=0.00217\n",
            "epoch=96 train_loss=1.18274 train_acc=0.88571 val_loss=1.56581 val_acc=0.71000 time=0.00215\n",
            "epoch=97 train_loss=1.21415 train_acc=0.85000 val_loss=1.56188 val_acc=0.71200 time=0.00215\n",
            "epoch=98 train_loss=1.19176 train_acc=0.85714 val_loss=1.55817 val_acc=0.71200 time=0.00218\n",
            "epoch=99 train_loss=1.20484 train_acc=0.87143 val_loss=1.55456 val_acc=0.71200 time=0.00223\n",
            "epoch=100 train_loss=1.17985 train_acc=0.88571 val_loss=1.55104 val_acc=0.71400 time=0.00222\n",
            "total training time=0.24409\n",
            "test_loss=1.53792 test_acc=0.74400 time=0.00064\n"
          ]
        }
      ]
    }
  ]
}